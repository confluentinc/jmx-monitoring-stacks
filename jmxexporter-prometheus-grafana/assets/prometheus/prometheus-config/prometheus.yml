global:
  scrape_interval:     60s # By default, scrape targets every 15 seconds.
  evaluation_interval: 15s # By default, scrape targets every 15 seconds.
  scrape_timeout: 30s # By default, scrape timeout is 10 seconds. But cp-demo is using cpu throttling, so let's leave enough time to fetch the metrics in particular for the first time as it needs to compile all rexps.

rule_files:
  - 'alert.rules'

alerting:
  alertmanagers:
  - scheme: http
    static_configs:
    - targets:
      - "alertmanager:9093"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
    - targets: ['localhost:9090']

  - job_name: 'node-exporter'
    static_configs:
    - targets: ['node-exporter:9100']

  - job_name: 'kafka'
    static_configs:
    - targets:
      - 'kafka1:1234'
      - 'kafka2:1234'
      labels:
        env: 'dev'

  - job_name: 'zookeeper'
    static_configs:
    - targets:
      - 'zookeeper:1234'
      labels:
        env: 'dev'

# No producer for the moment in cp-demo
#  - job_name: 'producer'
#    static_configs:
#      - targets:
#          - 'producer:1234'
#        labels:
#          env: 'dev'

# No consumer for the moment in cp-demo
#  - job_name: 'consumer'
#    static_configs:
#      - targets:
#          - "consumer:1234"
#        labels:
#          env: 'dev'

  - job_name: 'kafka-lag-exporter'
    static_configs:
      - targets:
        - 'kafka-lag-exporter:9999'
        labels:
           env: 'dev'
